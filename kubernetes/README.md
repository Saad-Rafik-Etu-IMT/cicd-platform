# ‚ò∏Ô∏è Guide Complet - D√©ploiement Kubernetes CI/CD Platform

**Objectif :** D√©ployer la plateforme CI/CD sur un cluster Kubernetes pour une scalabilit√© et r√©silience optimales.

**Dur√©e estim√©e :** 20-30 minutes

---

## üìã Table des Mati√®res

1. [Pr√©sentation](#1--pr√©sentation)
2. [Architecture Kubernetes](#2--architecture-kubernetes)
3. [Pr√©requis](#3--pr√©requis)
4. [Installation du Cluster](#4--installation-du-cluster)
5. [Construction des Images](#5--construction-des-images)
6. [D√©ploiement](#6--d√©ploiement)
7. [Acc√®s aux Services](#7--acc√®s-aux-services)
8. [Configuration Avanc√©e](#8--configuration-avanc√©e)
9. [Monitoring & Observabilit√©](#9--monitoring--observabilit√©)
10. [S√©curit√©](#10--s√©curit√©)
11. [Auto-scaling](#11--auto-scaling)
12. [Mises √† jour & Rollback](#12--mises-√†-jour--rollback)
13. [D√©pannage](#13--d√©pannage)
14. [Commandes Utiles](#14--commandes-utiles)

---

## 1. üéØ Pr√©sentation

### Pourquoi Kubernetes ?

| Aspect | Docker Compose | Kubernetes |
|--------|----------------|------------|
| **Scalabilit√©** | Manuelle | Automatique (HPA) |
| **Haute disponibilit√©** | ‚ùå | ‚úÖ Multi-replicas |
| **Rolling updates** | Basique | ‚úÖ Zero-downtime |
| **Self-healing** | ‚ùå | ‚úÖ Restart automatique |
| **Load balancing** | Manuel | ‚úÖ Int√©gr√© |
| **Secrets management** | Fichiers .env | ‚úÖ Secrets K8s |
| **Complexit√©** | Simple | Moyenne |

**‚û°Ô∏è Recommandation :** Kubernetes pour la production, Docker Compose pour le d√©veloppement local.

### Structure des Fichiers

```
kubernetes/
‚îú‚îÄ‚îÄ üìÅ Manifests principaux
‚îÇ   ‚îú‚îÄ‚îÄ namespace.yaml              # Namespace d√©di√© cicd-platform
‚îÇ   ‚îú‚îÄ‚îÄ configmap.yaml              # Configuration des applications
‚îÇ   ‚îú‚îÄ‚îÄ postgres-init-configmap.yaml # Script init PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ secrets.yaml                # Credentials & tokens
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ postgres.yaml               # üóÑÔ∏è PostgreSQL (CI/CD DB)
‚îÇ   ‚îú‚îÄ‚îÄ redis.yaml                  # üìÆ Redis (Queue jobs)
‚îÇ   ‚îú‚îÄ‚îÄ backend.yaml                # ‚öôÔ∏è API Backend Node.js
‚îÇ   ‚îú‚îÄ‚îÄ frontend.yaml               # üåê Dashboard React/Nginx
‚îÇ   ‚îú‚îÄ‚îÄ sonarqube.yaml              # üìä SonarQube + PostgreSQL
‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ üìÅ Optionnels
‚îÇ   ‚îú‚îÄ‚îÄ ingress.yaml                # üåç Ingress Controller
‚îÇ   ‚îú‚îÄ‚îÄ hpa.yaml                    # ‚ö° Horizontal Pod Autoscaler
‚îÇ   ‚îú‚îÄ‚îÄ network-policy.yaml         # üîí Politiques r√©seau
‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ üìÅ Outils
‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml          # Configuration Kustomize
‚îÇ   ‚îú‚îÄ‚îÄ deploy.sh                   # Script d√©ploiement (Linux/Mac)
‚îÇ   ‚îú‚îÄ‚îÄ deploy.ps1                  # Script d√©ploiement (Windows)
‚îÇ   ‚îî‚îÄ‚îÄ README.md                   # Cette documentation
```

---

## 2. üèóÔ∏è Architecture Kubernetes

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                            KUBERNETES CLUSTER                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                      Namespace: cicd-platform                          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Ingress    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Frontend   ‚îÇ     ‚îÇ       SonarQube         ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Controller ‚îÇ     ‚îÇ  (2 pods)   ‚îÇ     ‚îÇ       (1 pod)           ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                   ‚îÇ                        ‚îÇ                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                   ‚îÇ                        ‚ñº                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                   ‚îÇ            ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                   ‚îÇ            ‚îÇ   SonarQube DB          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚ñº                   ‚ñº            ‚îÇ   (PostgreSQL)          ‚îÇ  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         Backend API             ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ         (2 pods, HPA)           ‚îÇ                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ                                                         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     ‚ñº               ‚ñº                                                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇPostgreSQL‚îÇ  ‚îÇ  Redis   ‚îÇ                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  (1 pod) ‚îÇ  ‚îÇ  (1 pod) ‚îÇ                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ   PVC    ‚îÇ  ‚îÇ   PVC    ‚îÇ                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                                        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Services et Ports

| Service | Type | Port Interne | NodePort | Description |
|---------|------|--------------|----------|-------------|
| `cicd-frontend` | ClusterIP + NodePort | 80 | 30000 | Dashboard React |
| `cicd-backend` | ClusterIP + NodePort | 3002 | 30002 | API + WebSocket |
| `cicd-sonarqube` | ClusterIP + NodePort | 9000 | 30090 | Analyse qualit√© |
| `cicd-postgres` | ClusterIP | 5432 | - | Base de donn√©es |
| `cicd-redis` | ClusterIP | 6379 | - | Queue jobs |
| `sonar-db` | ClusterIP | 5432 | - | DB SonarQube |

---

## 3. üõ†Ô∏è Pr√©requis

### Outils requis

| Outil | Version | Usage | Installation |
|-------|---------|-------|--------------|
| **kubectl** | 1.28+ | CLI Kubernetes | [Guide](https://kubernetes.io/docs/tasks/tools/) |
| **Docker** | 24+ | Build images | [Guide](https://docs.docker.com/get-docker/) |
| **Cluster K8s** | 1.28+ | Infrastructure | Voir section 4 |

### V√©rification des pr√©requis

```powershell
# Windows PowerShell
kubectl version --client
docker --version
```

```bash
# Linux/Mac
kubectl version --client
docker --version
```

**‚úÖ Sortie attendue :**
```
Client Version: v1.28.x
Docker version 24.x.x
```

---

## 4. üì¶ Installation du Cluster

### Option A : Docker Desktop (Windows/Mac) ‚≠ê Recommand√©

**√âtape 1 : Activer Kubernetes**
1. Ouvrir Docker Desktop
2. Aller dans **Settings** (‚öôÔ∏è) ‚Üí **Kubernetes**
3. Cocher **"Enable Kubernetes"**
4. Cliquer **"Apply & Restart"**
5. Attendre que le statut passe au vert (2-5 min)

**√âtape 2 : V√©rifier l'installation**
```powershell
kubectl cluster-info
kubectl get nodes
```

**‚úÖ Sortie attendue :**
```
Kubernetes control plane is running at https://kubernetes.docker.internal:6443
NAME             STATUS   ROLES           AGE   VERSION
docker-desktop   Ready    control-plane   1m    v1.28.x
```

---

### Option B : Minikube (Toutes plateformes)

**√âtape 1 : Installation**

```powershell
# Windows (PowerShell Admin)
choco install minikube -y
# OU via winget
winget install Kubernetes.minikube
```

```bash
# Linux
curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo install minikube-linux-amd64 /usr/local/bin/minikube

# Mac
brew install minikube
```

**√âtape 2 : D√©marrer le cluster**
```bash
minikube start --cpus=4 --memory=8192 --driver=docker
```

**√âtape 3 : Activer les addons**
```bash
minikube addons enable ingress
minikube addons enable metrics-server
```

**‚úÖ V√©rification :**
```bash
minikube status
kubectl get nodes
```

---

### Option C : Kind (Kubernetes in Docker)

```bash
# Installation
curl -Lo ./kind https://kind.sigs.k8s.io/dl/v0.20.0/kind-linux-amd64
chmod +x ./kind
sudo mv ./kind /usr/local/bin/kind

# Cr√©er un cluster
kind create cluster --name cicd-cluster
```

---

## 5. üî® Construction des Images

### ‚ö†Ô∏è Important pour Minikube
Pour que Minikube utilise les images locales :
```bash
eval $(minikube docker-env)
```

### √âtape 5.1 : Construire l'image Backend

```powershell
# Windows PowerShell
cd c:\Users\QL6479\SchoolDevs\Devops\cicd-platform\backend
docker build -t cicd-backend:latest .
```

```bash
# Linux/Mac
cd ~/cicd-platform/backend
docker build -t cicd-backend:latest .
```

**‚úÖ V√©rification :**
```bash
docker images | grep cicd-backend
```

### √âtape 5.2 : Construire l'image Frontend

```powershell
# Windows PowerShell
cd c:\Users\QL6479\SchoolDevs\Devops\cicd-platform\frontend
docker build -t cicd-frontend:latest `
  --build-arg VITE_API_URL=http://localhost:30002 `
  --build-arg VITE_WS_URL=ws://localhost:30002 .
```

```bash
# Linux/Mac
cd ~/cicd-platform/frontend
docker build -t cicd-frontend:latest \
  --build-arg VITE_API_URL=http://localhost:30002 \
  --build-arg VITE_WS_URL=ws://localhost:30002 .
```

**‚úÖ V√©rification :**
```bash
docker images | grep cicd
```

**Sortie attendue :**
```
cicd-backend    latest   abc123   1 minute ago   250MB
cicd-frontend   latest   def456   1 minute ago   50MB
```

---

## 6. üöÄ D√©ploiement

### Option 1 : Script automatis√© ‚≠ê Recommand√©

**Windows PowerShell :**
```powershell
cd c:\Users\QL6479\SchoolDevs\Devops\cicd-platform\kubernetes
.\deploy.ps1 deploy
```

**Linux/Mac :**
```bash
cd kubernetes
chmod +x deploy.sh
./deploy.sh deploy
```

---

### Option 2 : Kustomize

```bash
kubectl apply -k kubernetes/
```

---

### Option 3 : D√©ploiement manuel √©tape par √©tape

**√âtape 6.1 : Cr√©er le namespace**
```bash
kubectl apply -f namespace.yaml
```

**√âtape 6.2 : Appliquer les configurations**
```bash
kubectl apply -f configmap.yaml
kubectl apply -f postgres-init-configmap.yaml
kubectl apply -f secrets.yaml
```

**√âtape 6.3 : D√©ployer les bases de donn√©es**
```bash
kubectl apply -f postgres.yaml
kubectl apply -f redis.yaml

# Attendre que PostgreSQL soit pr√™t (‚è≥ ~60s)
kubectl wait --for=condition=ready pod -l app=cicd-postgres -n cicd-platform --timeout=120s
kubectl wait --for=condition=ready pod -l app=cicd-redis -n cicd-platform --timeout=60s
```

**√âtape 6.4 : D√©ployer SonarQube**
```bash
kubectl apply -f sonarqube.yaml

# ‚è≥ SonarQube prend 2-3 minutes √† d√©marrer
kubectl wait --for=condition=ready pod -l app=cicd-sonarqube -n cicd-platform --timeout=300s
```

**√âtape 6.5 : D√©ployer l'application**
```bash
kubectl apply -f backend.yaml
kubectl apply -f frontend.yaml

kubectl wait --for=condition=ready pod -l app=cicd-backend -n cicd-platform --timeout=120s
kubectl wait --for=condition=ready pod -l app=cicd-frontend -n cicd-platform --timeout=60s
```

**‚úÖ V√©rification finale :**
```bash
kubectl get all -n cicd-platform
```

**Sortie attendue :**
```
NAME                                  READY   STATUS    RESTARTS   AGE
pod/cicd-backend-xxx                  1/1     Running   0          2m
pod/cicd-backend-yyy                  1/1     Running   0          2m
pod/cicd-frontend-xxx                 1/1     Running   0          1m
pod/cicd-frontend-yyy                 1/1     Running   0          1m
pod/cicd-postgres-xxx                 1/1     Running   0          3m
pod/cicd-redis-xxx                    1/1     Running   0          3m
pod/cicd-sonarqube-xxx                1/1     Running   0          3m
pod/sonar-db-xxx                      1/1     Running   0          3m

NAME                           TYPE        CLUSTER-IP       PORT(S)
service/cicd-backend           ClusterIP   10.96.x.x        3002/TCP
service/cicd-backend-nodeport  NodePort    10.96.x.x        3002:30002/TCP
service/cicd-frontend          ClusterIP   10.96.x.x        80/TCP
service/cicd-frontend-nodeport NodePort    10.96.x.x        80:30000/TCP
service/cicd-sonarqube         ClusterIP   10.96.x.x        9000/TCP
...
```

---

## 7. üåê Acc√®s aux Services

### M√©thode 1 : NodePort (D√©veloppement) ‚≠ê

| Service | URL |
|---------|-----|
| **Frontend** | http://localhost:30000 |
| **Backend API** | http://localhost:30002 |
| **SonarQube** | http://localhost:30090 |

> üí° **Docker Desktop** : Utilisez `localhost`
> üí° **Minikube** : Utilisez `$(minikube ip)` ou `minikube service cicd-frontend-nodeport -n cicd-platform`

---

### M√©thode 2 : Port-Forward (Recommand√© pour debug)

Ouvrez 3 terminaux :

**Terminal 1 - Frontend :**
```bash
kubectl port-forward svc/cicd-frontend 3000:80 -n cicd-platform
```
‚û°Ô∏è http://localhost:3000

**Terminal 2 - Backend :**
```bash
kubectl port-forward svc/cicd-backend 3002:3002 -n cicd-platform
```
‚û°Ô∏è http://localhost:3002

**Terminal 3 - SonarQube :**
```bash
kubectl port-forward svc/cicd-sonarqube 9000:9000 -n cicd-platform
```
‚û°Ô∏è http://localhost:9000 (admin/admin)

---

### M√©thode 3 : Ingress (Production)

**√âtape 1 : Installer l'Ingress Controller**
```bash
kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml
```

**√âtape 2 : Appliquer l'Ingress**
```bash
kubectl apply -f ingress.yaml
```

**√âtape 3 : Configurer les DNS/hosts**

Ajoutez dans `/etc/hosts` (Linux/Mac) ou `C:\Windows\System32\drivers\etc\hosts` (Windows) :
```
127.0.0.1 cicd.local api.cicd.local sonar.cicd.local
```

**Acc√®s :**
- http://cicd.local ‚Üí Frontend
- http://api.cicd.local ‚Üí Backend
- http://sonar.cicd.local ‚Üí SonarQube

---

## 8. ‚öôÔ∏è Configuration Avanc√©e

### Variables d'environnement

Modifiez `configmap.yaml` :

```yaml
data:
  # Mode pipeline
  PIPELINE_MODE: "real"          # simulate | real
  
  # URLs (adapter selon votre setup)
  FRONTEND_URL: "http://cicd-frontend:80"
  BACKEND_URL: "http://cicd-backend:3002"
  
  # VM de d√©ploiement
  VM_HOST: "192.168.1.100"
  VM_USER: "deployer"
```

Appliquer les changements :
```bash
kubectl apply -f configmap.yaml
kubectl rollout restart deployment/cicd-backend -n cicd-platform
```

---

### Secrets (Production)

‚ö†Ô∏è **Ne jamais commiter les vrais secrets !**

**Cr√©er des secrets encod√©s en base64 :**
```bash
echo -n "mon-mot-de-passe" | base64
# Output: bW9uLW1vdC1kZS1wYXNzZQ==
```

**Ou utiliser un gestionnaire de secrets :**
- **HashiCorp Vault**
- **Azure Key Vault**
- **AWS Secrets Manager**
- **Sealed Secrets** (Bitnami)

---

### Ressources (ajuster selon le cluster)

| Composant | CPU Request | CPU Limit | Memory Request | Memory Limit |
|-----------|-------------|-----------|----------------|--------------|
| Backend | 200m | 500m | 256Mi | 512Mi |
| Frontend | 50m | 100m | 64Mi | 128Mi |
| PostgreSQL | 250m | 500m | 256Mi | 512Mi |
| Redis | 100m | 200m | 128Mi | 256Mi |
| SonarQube | 500m | 2000m | 2Gi | 4Gi |

---

## 9. üìä Monitoring & Observabilit√©

### V√©rifier le statut des pods

```bash
# Vue d'ensemble
kubectl get pods -n cicd-platform -o wide

# D√©tails d'un pod
kubectl describe pod <pod-name> -n cicd-platform

# √âv√©nements r√©cents
kubectl get events -n cicd-platform --sort-by='.lastTimestamp'
```

### Consulter les logs

```bash
# Logs du backend
kubectl logs -f deployment/cicd-backend -n cicd-platform

# Logs du frontend
kubectl logs -f deployment/cicd-frontend -n cicd-platform

# Logs d'un pod sp√©cifique
kubectl logs -f <pod-name> -n cicd-platform

# Logs pr√©c√©dents (si crash)
kubectl logs <pod-name> -n cicd-platform --previous
```

### M√©triques CPU/M√©moire

```bash
# Installer metrics-server (si pas install√©)
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml

# Voir les m√©triques
kubectl top pods -n cicd-platform
kubectl top nodes
```

**Sortie exemple :**
```
NAME                              CPU(cores)   MEMORY(bytes)
cicd-backend-xxx                  25m          128Mi
cicd-frontend-xxx                 5m           32Mi
cicd-postgres-xxx                 50m          256Mi
```

---

## 10. üîí S√©curit√©

### Network Policies

Restreindre le trafic entre les pods :

```bash
kubectl apply -f network-policy.yaml
```

**R√®gles appliqu√©es :**
- ‚úÖ Frontend ‚Üí Backend uniquement
- ‚úÖ Backend ‚Üí PostgreSQL, Redis, SonarQube
- ‚úÖ SonarQube ‚Üí SonarQube DB
- ‚ùå Pas d'acc√®s direct aux bases de donn√©es depuis l'ext√©rieur

### RBAC (Role-Based Access Control)

Cr√©er un utilisateur avec acc√®s limit√© :

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: cicd-platform
  name: cicd-viewer
rules:
- apiGroups: [""]
  resources: ["pods", "services", "configmaps"]
  verbs: ["get", "list", "watch"]
```

### Pod Security Standards

Ajouter aux Deployments :

```yaml
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        fsGroup: 1000
      containers:
      - name: app
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
              - ALL
```

---

## 11. ‚ö° Auto-scaling

### Horizontal Pod Autoscaler (HPA)

```bash
kubectl apply -f hpa.yaml
```

**Configuration :**

| Deployment | Min Pods | Max Pods | CPU Target | Memory Target |
|------------|----------|----------|------------|---------------|
| Backend | 2 | 10 | 70% | 80% |
| Frontend | 2 | 5 | 70% | - |

**V√©rifier le HPA :**
```bash
kubectl get hpa -n cicd-platform
```

**Sortie :**
```
NAME               REFERENCE                  TARGETS   MINPODS   MAXPODS   REPLICAS
cicd-backend-hpa   Deployment/cicd-backend    25%/70%   2         10        2
cicd-frontend-hpa  Deployment/cicd-frontend   10%/70%   2         5         2
```

### Test de charge

```bash
# Simuler une charge
kubectl run -i --tty load-generator --rm --image=busybox --restart=Never -- \
  /bin/sh -c "while true; do wget -q -O- http://cicd-backend.cicd-platform:3002/health; done"
```

Observer le scaling :
```bash
kubectl get hpa -n cicd-platform -w
```

---

## 12. üîÑ Mises √† jour & Rollback

### Rolling Update (Zero-downtime)

```bash
# Mettre √† jour l'image
kubectl set image deployment/cicd-backend backend=cicd-backend:v2 -n cicd-platform

# Suivre le d√©ploiement
kubectl rollout status deployment/cicd-backend -n cicd-platform
```

**Sortie :**
```
Waiting for deployment "cicd-backend" rollout to finish: 1 old replicas are pending termination...
Waiting for deployment "cicd-backend" rollout to finish: 1 of 2 updated replicas are available...
deployment "cicd-backend" successfully rolled out
```

### Historique des d√©ploiements

```bash
kubectl rollout history deployment/cicd-backend -n cicd-platform
```

**Sortie :**
```
REVISION  CHANGE-CAUSE
1         <none>
2         kubectl set image deployment/cicd-backend backend=cicd-backend:v2
```

### Rollback

```bash
# Rollback √† la version pr√©c√©dente
kubectl rollout undo deployment/cicd-backend -n cicd-platform

# Rollback √† une version sp√©cifique
kubectl rollout undo deployment/cicd-backend -n cicd-platform --to-revision=1
```

---

## 13. üîß D√©pannage

### ‚ùå Pod en CrashLoopBackOff

```bash
# Voir les logs du crash
kubectl logs <pod-name> -n cicd-platform --previous

# Voir les √©v√©nements
kubectl describe pod <pod-name> -n cicd-platform
```

**Causes courantes :**
- Image non trouv√©e ‚Üí V√©rifier le nom de l'image
- Erreur de configuration ‚Üí V√©rifier ConfigMap/Secrets
- Port d√©j√† utilis√© ‚Üí V√©rifier les ports
- Ressources insuffisantes ‚Üí Augmenter les limits

---

### ‚ùå Pod en Pending

```bash
kubectl describe pod <pod-name> -n cicd-platform | grep -A 10 Events
```

**Causes courantes :**
- Pas assez de ressources sur le n≈ìud
- PVC en attente ‚Üí `kubectl get pvc -n cicd-platform`
- NodeSelector non satisfait

---

### ‚ùå Service inaccessible

```bash
# V√©rifier les endpoints
kubectl get endpoints -n cicd-platform

# V√©rifier le service
kubectl describe svc cicd-backend -n cicd-platform

# Test depuis un pod
kubectl run -it --rm debug --image=busybox --restart=Never -- \
  wget -qO- http://cicd-backend.cicd-platform:3002/health
```

---

### ‚ùå SonarQube ne d√©marre pas

SonarQube n√©cessite des param√®tres kernel sp√©cifiques :

```bash
# Sur le n≈ìud (ou dans le initContainer)
sudo sysctl -w vm.max_map_count=524288
sudo sysctl -w fs.file-max=131072

# Pour persister (ajouter dans /etc/sysctl.conf)
vm.max_map_count=524288
fs.file-max=131072
```

---

### ‚ùå PVC en Pending

```bash
kubectl get pvc -n cicd-platform
kubectl describe pvc <pvc-name> -n cicd-platform

# V√©rifier les StorageClass disponibles
kubectl get storageclass
```

**Solution Docker Desktop :**
```bash
# Utiliser le StorageClass par d√©faut
kubectl patch pvc <pvc-name> -n cicd-platform -p '{"spec":{"storageClassName":"hostpath"}}'
```

---

## 14. üìù Commandes Utiles

### Cheatsheet

```bash
# ============= D√âPLOIEMENT =============
kubectl apply -k kubernetes/              # D√©ployer tout
kubectl delete namespace cicd-platform    # Supprimer tout

# ============= STATUS =============
kubectl get all -n cicd-platform          # Tout voir
kubectl get pods -n cicd-platform -w      # Watch mode
kubectl top pods -n cicd-platform         # M√©triques

# ============= LOGS =============
kubectl logs -f deploy/cicd-backend -n cicd-platform
kubectl logs <pod> -n cicd-platform --previous

# ============= DEBUG =============
kubectl exec -it <pod> -n cicd-platform -- /bin/sh
kubectl describe pod <pod> -n cicd-platform
kubectl get events -n cicd-platform --sort-by='.lastTimestamp'

# ============= PORT-FORWARD =============
kubectl port-forward svc/cicd-frontend 3000:80 -n cicd-platform
kubectl port-forward svc/cicd-backend 3002:3002 -n cicd-platform
kubectl port-forward svc/cicd-sonarqube 9000:9000 -n cicd-platform

# ============= SCALING =============
kubectl scale deployment cicd-backend --replicas=3 -n cicd-platform
kubectl get hpa -n cicd-platform

# ============= UPDATES =============
kubectl set image deploy/cicd-backend backend=cicd-backend:v2 -n cicd-platform
kubectl rollout status deploy/cicd-backend -n cicd-platform
kubectl rollout undo deploy/cicd-backend -n cicd-platform
```

---

## ‚úÖ CHECKLIST D√âPLOIEMENT

### Avant le d√©ploiement
- [ ] Cluster Kubernetes actif (`kubectl cluster-info`)
- [ ] Docker install√© et fonctionnel
- [ ] Images construites (`docker images | grep cicd`)

### Pendant le d√©ploiement
- [ ] Namespace cr√©√© (`kubectl get ns cicd-platform`)
- [ ] ConfigMaps et Secrets appliqu√©s
- [ ] PostgreSQL et Redis en Running
- [ ] SonarQube en Running (‚è≥ 2-3 min)
- [ ] Backend et Frontend en Running

### Apr√®s le d√©ploiement
- [ ] Frontend accessible (http://localhost:30000)
- [ ] Backend API r√©pond (`curl http://localhost:30002/health`)
- [ ] SonarQube accessible (http://localhost:30090)
- [ ] WebSocket fonctionne

---

## üìö Ressources

- [Kubernetes Documentation](https://kubernetes.io/docs/)
- [Kustomize Documentation](https://kustomize.io/)
- [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/)
- [Kubernetes Secrets Best Practices](https://kubernetes.io/docs/concepts/configuration/secret/#best-practices)
- [HPA Documentation](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)

---

**üéâ F√©licitations ! Votre plateforme CI/CD est maintenant d√©ploy√©e sur Kubernetes !**
